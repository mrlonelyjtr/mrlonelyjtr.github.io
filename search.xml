<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Torch Demo]]></title>
      <url>%2F2017%2F03%2F18%2FTorch-Demo%2F</url>
      <content type="text"><![CDATA[We have 5 steps to do in training a torch neural network. (1) Load and normalize data; (2) Define Neural Network; (3) Define Loss function; (4) Train network on training data; (5) Test network on test data. Tutorialcvpr2015/Deep Learning with Torch.ipynb Code12345require 'paths'require 'nn'require 'torch'require 'cunn'require 'cutorch' Load and normalize data12345678910111213141516171819if (not paths.filep("cifar10torchsmall.zip")) then os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip') os.execute('unzip cifar10torchsmall.zip')endtrainset = torch.load('cifar10-train.t7')testset = torch.load('cifar10-test.t7')classes = &#123;'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'&#125;setmetatable(trainset, &#123;__index = function(t, i) return &#123;t.data[i], t.label[i]&#125; end&#125;);function trainset:size() return self.data:size(1)end 1234567891011121314151617trainset.data = trainset.data:double()testset.data = testset.data:double()mean = &#123;&#125;stdv = &#123;&#125;for i=1,3 do mean[i] = trainset.data[&#123; &#123;&#125;, &#123;i&#125;, &#123;&#125;, &#123;&#125; &#125;]:mean() --print('Channel ' .. i .. ', Mean: ' .. mean[i]) trainset.data[&#123; &#123;&#125;, &#123;i&#125;, &#123;&#125;, &#123;&#125; &#125;]:add(-mean[i]) stdv[i] = trainset.data[&#123; &#123;&#125;, &#123;i&#125;, &#123;&#125;, &#123;&#125; &#125;]:std() --print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i]) trainset.data[&#123; &#123;&#125;, &#123;i&#125;, &#123;&#125;, &#123;&#125; &#125;]:div(stdv[i])endfor i=1,3 do testset.data[&#123; &#123;&#125;, &#123;i&#125;, &#123;&#125;, &#123;&#125; &#125;]:add(-mean[i]) testset.data[&#123; &#123;&#125;, &#123;i&#125;, &#123;&#125;, &#123;&#125; &#125;]:div(stdv[i])end Define neural network1234567891011121314net = nn.Sequential()net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernelnet:add(nn.ReLU()) -- non-linearitynet:add(nn.SpatialMaxPooling(2,2,2,2)) -- A max-pooling operation that looks at 2x2 windows and finds the max.net:add(nn.SpatialConvolution(6, 16, 5, 5))net:add(nn.ReLU()) -- non-linearitynet:add(nn.SpatialMaxPooling(2,2,2,2))net:add(nn.View(16*5*5)) -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5net:add(nn.Linear(16*5*5, 120)) -- fully connected layer (matrix multiplication between input and weights)net:add(nn.ReLU()) -- non-linearitynet:add(nn.Linear(120, 84))net:add(nn.ReLU()) -- non-linearitynet:add(nn.Linear(84, 10)) -- 10 is the number of outputs of the network (in this case, 10 digits)net:add(nn.LogSoftMax()) -- converts the output to a log-probability. Useful for classification problems Define the Loss function1criterion = nn.ClassNLLCriterion() Train the neural network1234trainer = nn.StochasticGradient(net, criterion)trainer.learningRate = 0.001trainer.maxIteration = 5trainer:train(trainset) 1234567-- train on GPUnet = net:cuda()criterion = criterion:cuda()trainset.data = trainset.data:cuda()trainset.label = trainset.label:cuda()testset.data = testset.data:cuda()testset.label = testset.label:cuda() Test the network, print accuracy12345678910111213141516correct = 0class_performance = &#123;0, 0, 0, 0, 0, 0, 0, 0, 0, 0&#125;for i=1,10000 do local groundtruth = testset.label[i] local prediction = net:forward(testset.data[i]) local confidences, indices = torch.sort(prediction, true) -- true means sort in descending order if groundtruth == indices[1] then correct = correct + 1 class_performance[groundtruth] = class_performance[groundtruth] + 1 endendprint(correct, 100*correct/10000 .. " % ")for i=1,#classes do print(classes[i], 100*class_performance[i]/1000 .. ' %')end ResultIt’ll take around 30 minutes to get the result on CPU. However, it’ll cost less than 10 minutes on GPU. 1th filename.lua On CPU On GPU]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F03%2F17%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
